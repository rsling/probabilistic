\section{Future directions}
\label{sec:futuredirections}

My and my co-author's research collected here shows that German has a wide range of phenomena to offer for examination under a usage-based probabilistic perspective.
Furthermore, in the form of the DECOW corpus, a now-proven source of data exists which allows researchers to work on these phenomena.
Based on the argumentation in Sections~\ref{sec:probabilisticgrammar}--\ref{sec:casestudies} and the case studies, a number of open research questions come to mind.
I see at least the following ones.

\vspace{\baselineskip}

\begin{itemize}
  \item The literature on \textit{cases of doubt} in German is famously rich.
    It would be beneficial for linguists working on German, corpus linguists, and linguists working in the cognitively oriented\slash usage-based tradition to examine them using the framework established here.
  \item The effects of corpus composition and the availability of metadata on corpus samples and sampling procedures should be examined further.
    The BNC is rich in metadata and has a well-planned composition, but for many other languages (like German), similar corpora do not exist.
  \item Related to the last point, corpora containing non-standard writing should be honoured more as a unique source of data.
    While there is a community working on such corpora and specific analyses of their content, many more (corpus) linguists could benefit from using them in the same way I did.
  \item Also related to this point, the usage-based perspective on graphemics as developed by Ulrike Sayatz and me should be developed and expanded further.
    Speakers' writing behaviour provides important clues to how they cognitively represent morphological and syntactic categories.
  \item Individual grammatical differences urgently require more attention.
    While it will probably be impossible to build large enough general-purpose corpora with speaker metadata which would allow research on individual grammatical differences, corpus data should be correlated with the reactions of individual speakers in controlled experiments.
  \item The prototype vs.\ exemplar debate would benefit from more large-scale corpus studies which must then be cross-validated in controlled experiments.
    Corpus data alone cannot provide evidence for or against one theory or the other.
  \item Statistical methods need to be scrutinised.
    While mindless applications of NHST are detrimental for valid scientific inferences, some critiques of frequentist statistics (language is never random; model everything) have gone too far or are understood in a much too unrestricted manner.
    Also, some currently-hyped alternative methods do not lead to substantially different results, are understood even less than traditional methods, and distract from the real problems with statistical inference.
\end{itemize}

\vspace{\baselineskip}

Clearly, my work has contributed to all of these points, but the overall situation in probabilistic, usage-based, cognitively oriented corpus linguistics is one where methods and theories are still in a very early stage of development.
