\section{Conclusions}
\label{sec:conclusion}

The studies reported in Sections~\ref{sec:corpusstudies} and~\ref{sec:experimental} have confirmed the theoretical model proposed in Section~\ref{sec:germanmeasurenps}, which predicted prototype effects and exemplar effects to jointly determine which of the two alternating constructions is chosen.
More specifically, the pre-study and the main study provided evidence that the NAC constructions favour more strongly grammaticalised measure nouns, modification by cardinals, and styles where the genitive is underrepresented and the text is less coherently and elaborately written.
The overall convergence between the pre-study and the main study and the convergence between corpus data and the experimental cross-validation strengthen the validity of this study.
Also, the fact that the result for \textit{Measurecase} converged with previous research \citep{Zimmer2015} lends credibility to the results.

Many relevant conclusions can be drawn based on the research presented here.
Although direct inferences from corpus data to mental representations are problematic (see Section~\ref{sec:cogocl}), the two attraction features (\textit{Kindattraction} and \textit{Measureattraction}) are virtually impossible to conceive of as prototype effects and thus favour an exemplar view or a mixed exemplar-prototype view.
As discussed in Section~\ref{sec:cogocl}, it is unnecessary to follow an extreme route, be it radical prototype theory or radical exemplar theory, given recent developments in cognitive science and cognitive linguistics.
While it is surely an intentionally overstated comment, \citet[15]{Kapatsinski2014} even suggests that ``in the extreme, some speakers’ heads could host exemplar models, and some could contain fairly abstract grammars, and the produced output would be essentially identical''.
If this is the case (even to a less extreme degree), corpora only provide pooled data averaged over speaker grammars with varying levels of abstraction.
Clearly, more research is required in this direction.

Another important aspect of the research presented here is the validation of the results derived from corpus data in two experimental paradigms.
While such cross-validations have been done (with varying success, see Section~\ref{sec:cogocl}) for over a decade, they have not yet become standard procedure.
As \citet[3--4]{DivjakEa2016a} put it:

\begin{quote}
  There are now a number of published multivariate models that use data, extracted from corpora [\ldots] to predict the choice for one morpheme, lexeme or construction over another.
  However, [\ldots] only a small number of these corpus-based studies have been cross-validated [\ldots].
  Of these cross-validated studies, few have directly evaluated the prediction accuracy of a complex, multivariate corpus-based model on humans using authentic corpus sentences [\ldots].
\end{quote}

The question now arises whether convergence was reached in the present case or not.
The answer is a clear yes.
The predictions made by the corpus-based model were a significant factor, both in the more explicit paradigm (forced choice) and the implicit paradigm (self-paced reading).
This shows that the model indeed partially predicts the variant which language users expect.
The overall effect as measured in the $R^2$ was acceptable but not strong (roughly 0.2) in both cases, however.
While this could be traced back at least partially to one suboptimally chosen stimulus, we really need to consider what kind of convergence we expect to see between corpus data and experiments.
The main corpus study had $R^2_m=0.409$ and $R^2_c=0.495$, which is good but not anywhere near a perfect fit.
With the added inter-speaker variability brought into play by the experimental setup (compared to the averaging across thousands of speakers in the corpus study), a perfect fit cannot be expected.
Furthermore, like many alternations in German which are often labelled as \textit{Zweifelsfälle} (`cases of doubt') in the traditional literature \citep{Duden09,Klein2009}, the MNP alternation is a case where speakers often have no clear intuition, and a lot of free variation seems to be involved.
Rarely do speakers feel that one alternative is clearly odd or ungrammatical.
Additionally, cases of doubt involving the genitive are often a matter of fierce normative public debate, and especially the forced choice paradigm does not effectively prevent participants from making normative judgements.
This might even account for the slightly better fit in the self-paced reading experiment, where normative considerations are suppressed.
Thus, the present study shows that what counts as convergence between corpus and experimental results should be gauged considering the nature of the phenomenon at hand, the source of the corpus data, and the experimental paradigm.
Clearly, more case studies using diverse and different corpora are needed, and it should become standard practice to cross-validate them using experimental methods.
Given that a single failure to achieve convergence does not provide conclusive evidence for divergence, many more studies need to be published to the point that meta-analysis becomes possible.%
\footnote{This is even more vital considering the variation in results from experimental work.
See, for example, the impressive list of different reading time results from ten papers on Chinese relative clause processing in \citet[8]{Vasishth2015}.}

On a larger methodological scale, this paper also makes a number of contributions.
The statistical model was a true multilevel model (see Section~\ref{sec:mainstudystatisticalmodel}), demonstrating how multilevel modelling helps to specify complex hierarchies of abstract features, item-specific tendencies, and exemplar effects at the level of observations (sentences; first level) and lemmas (second level).
\citet{Gries2015} still calls mixed models ``underused'' in corpus linguistics, and multilevel models are consequently also an underused tools.
At the same time, the ill effects of overparametrisation of mixed models with varying slopes as criticised by \citet{BatesEa2015a} were demonstrated.
Furthermore, fitting an additive model to the reading time data did not improve the fit as there were no non-linearities in the data.
While \citet{DivjakEa2016} also use attested sentences, they find that an additive model helped to deal with non-linearities.
This is clearly another area where only more studies can lead to clarification.
Finally, much like \citet{Dabrowska2014} found that speakers' knowledge of collocations was not matched by a set of standard measures of collocation strength extracted from corpora, a simple quotient based on raw frequencies for the attraction strength performed much better in the present study compared to collexeme strength in the form of logarithmised Fisher p-values. 
While this does not allow the conclusion that collexeme strength has no cognitive reality, it might indicate that for measuring attraction effects exerted by non-alternating constructions on alternating constructions, taking the marginals into account might not be crucial.%
\footnote{However, many different measures have been proposed within the collostructional framework (see \citealp{Gries2015b} for an overview of them and a defense of the framework).
Future research might show significant differences between them for the problem at hand.}

Besides the methodological aspects mentioned above, future work could extend the validity of the results presented here through a more in-depth look at stylistic or register effects, for example using the new Biber-style annotations \citep{Biber1988} which will be released with a new version of the DECOW corpus soon according to its creators.
A reviewer also pointed out that strongly lexicalised adjective-noun combinations like \textit{schwarzer Tee} `black tea' might have a tendency to occur in the \NACa\ because they have more compound-like qualities, blocking strong case inflection in between them.
While this potential effect was impossible to incorporate into the present study, it could be integrated into future research on the phenomenon.

In closing, I want to point out that the so-called cases of doubt in German morphosyntax -- like the measure noun phrase alternation -- are in fact ideal test cases for probabilistic modelling of alternation phenomena in cognitive linguistics.
Doing more research on them could help to provide answers to many of the fundamental and methodological issues raised here.
