<<setupweaknounsfrm, cache=FALSE, echo=FALSE, include=FALSE, results='asis'>>=
  opts_knit$set(self.contained=FALSE)
@

\chapter{Prototype-driven alternations: the case of German weak nouns}

\textbf{Abstract:} Over the past years, multifactorial corpus-based explorations of alternations in grammar have become an accepted major tool in cognitively oriented corpus linguistics. For example, prototype theory as a theory of similarity-based and inherently probabilistic linguistic categorization has received support from studies showing that alternating constructions and items often occur with probabilities influenced by prototypical formal, semantic or contextual factors. In this paper, I analyze a low-frequency alternation effect in German noun inflection in terms of prototype theory, based on strong hypotheses from the existing literature that I integrate into an established theoretical framework of usage-based probabilistic morphology, which allows us to account for similarity effects even in seemingly regular areas of the grammar. Specifically, the so-called \textit{weak} masculine nouns in German, which follow an unusual pattern of case marking and often have characteristic lexical properties, sporadically occur in forms of the dominant \textit{strong} masculine nouns. Using data from the nine-billion-token DECOW12A web corpus of contemporary German, I demonstrate that the probability of the alternation is influenced by the presence or absence of semantic, phonotactic, and paradigmatic features. Token frequency is also shown to have an effect on the alternation, in line with common assumptions about the relation between frequency and entrenchment. I use a version of prototype theory with weighted features and polycentric categories, but I also discuss the question of whether such corpus data can be taken as strong evidence for or against specific models of cognitive representation (prototypes vs. exemplars).

\section{Overview}

On July 23, 2012, the German online newspaper \textit{Spiegel} \textit{Online} published an article about a controversial statement made by Philipp Rösler, the former leader of the German Liberal Democratic Party. The article includes a comment from a fellow party member quoted in a headline as \REF{ex:key:1a}, but repeated in the text body as \REF{ex:key:1b}.\footnote{\url{http://www.spiegel.de/politik/deutschland/philipp-roesler-empoert-fdp-freunde-mit-griechenland-aeusserung-a-845980.html}}

\ea%1
    \label{ex:key:1}
    \gll\\
        \\
    \glt
    \z
          a.  Auf  welchem  \textbf{Planeten}  lebt  er?
on  which  planet  lives  he
‘What planet does he live on?’
b.  Auf  welchem  \textbf{Planet}  lebt  er?

In \REF{ex:key:1a}, the so-called weak masculine noun \textit{Planet} ‘planet’ takes the inflectional marker \textit{\nobreakdash-en} in the dative singular, but it does not in \REF{ex:key:1b}. The form in \REF{ex:key:1b} represents a non-standard alternation because dative singular forms without a suffix are characteristic of the much more productive strong masculine declension class, to which \textit{Planet} predominantly does not belong. While it is impossible to know (and irrelevant) which variant was originally uttered in this specific case, many native speakers would agree that dropping the \textit{\nobreakdash-en} does not lead to full unacceptability. Similar examples of an accusative singular and a genitive singular of a weak noun (\textit{Mensch} ‘human’) in strong forms (accusative \textit{Mensch} instead of \textit{Menschen} and genitive \textit{Mensches} instead of \textit{Menschen}) are shown in \REF{ex:key:2} and \REF{ex:key:3}.\footnote{http://www.flegel-g.de/wachstum-wachstum.html}\textsuperscript{,}\footnote{http://www.mumia.de/doc/aktuell/991201ai00.html} The two paradigms (standard and alternative) are shown in \tabref{tab:key:1}. Notice that the nominative singular and the whole plural are not affected. The remainder of the paper deals exclusively with the three non-nominative singular cases.

\ea%2
    \label{ex:key:2}
    \gll\\
        \\
    \glt
    \z
          Gibt  es  einen  Mensch,  der  stetig    wächst?
gives  it  a  human  who  constantly  grows
‘Is there any person who grows constantly?’

\ea%3
    \label{ex:key:3}
    \gll\\
        \\
    \glt
    \z
          Das  Leben  eines  Mensches  wird    zu  politischen  Zwecken
the  life    of.a  human  becomes  for  political  reasons
aufs    Spiel  gesetzt.
on.the  game  put
‘A person’s life is put at risk for political reasons.’


\begin{table}
\caption{The canonical weak and the alternative strong forms of weak nouns with the appropriate form of the masculine definite article \textit{der} ‘the’.}
\label{tab:1}
\end{table}

The (simplex) weak nouns form a small class of just over 450 masculine nouns. Interestingly, many of them, according to \citet{Köpcke1995}, have prototypical semantic and phonotactic properties such as human denotation or non-final accent (cf. \sectref{sec:key:2.4}). This makes the alternative forms, as seen in the sentences \REF{ex:key:1} to \REF{ex:key:3}, particularly interesting. Under classical Aristotelian theories of linguistic categorization, we could only classify the alternate forms as the results of \textit{performance} \textit{error}, while otherwise adhering to a notion of fully discrete grammatical categories not affected by prototypicality, similarity effects, or fuzziness. However, such an interpretation is revealed to be inappropriate if we can show that the presence or the absence of the prototypical semantic and phonotactic features influences the alternation strength of weak nouns.\footnote{By \textit{alternation} \textit{strength}, I mean the probability that a specific weak noun occurs in a strong form, possibly in a specific context.} After all, the term \textit{error} (as in \textit{performance} \textit{error}) can only refer to the unmodeled random component of an alternation phenomenon, which is essentially irrelevant from a theoretical perspective. To assume something like irrelevant effects which are not randomly distributed (or relevant effects which are randomly distributed) would be contradictory. The guiding hypothesis for this study is therefore clear: if there is a cognitively real prototype, then a weak noun’s probability of occurring in a strong form should be inversely correlated with its degree of prototypicality. In the spirit of similar corpus-linguistic approaches to alternations (e.g., \citealt{Gries2003}; \citealt{BresnanEtAl2007}; \citealt{NessetJanda2010}; \citealt{DivjakArppe2013}), I assume that corpora are a valid source of data to test such hypotheses, at least as long as we can find enough occurrences of both alternatives to allow for an appropriate type of statistical inference. Despite its apparent relevance for cognitively oriented corpus-based linguistics, the alternation strength of weak nouns in German has not yet been examined in a large-scale, methodologically sound corpus study. This situation might be partially attributed to the lack of appropriate corpora, and the present paper aims to remedy it by using a very large web corpus of German and by applying fully automatic methods of data retrieval and analysis.

The paper is structured as follows. In \sectref{sec:key:2}, I discuss the theoretical background in detail, i.e., relating to prototype theory as a theory of similarity-based categorization in the broad sense. I also argue for the validity of using corpora in prototype research, and recapitulate and extend the existing analyses of the weak-noun prototype in order to derive hypotheses for the corpus study. The corpus study is reported in \sectref{sec:key:3}, including a detailed description of the corpus resources and the methods applied to extract the data, as well as a report of an appropriate Generalized Linear Model and an interpretation of the results. Finally, I summarize the findings in \sectref{sec:key:4.}

\section{On prototypes, cognitive corpus-based morphology, and weak nouns}

\subsection{Prototype theory}

As mentioned in the previous section, the main hypotheses for this study have been previously formulated within prototype theory \citep{Köpcke1995}. Therefore, I will briefly introduce the relevant ideas from prototype theory in this section.\footnote{Convenient overviews can be found, e.g., in \citet{Taylor2003a}, \citet{Taylor2008}, \citet{Taylor2015}.} According to formal approaches to linguistic categorization inspired by Aristotelian logic, category membership is determined by rules and defining features, and it is consequently not viewed as a matter of degree (\citealt{Sutcliffe1993}; \citealt{Murphy2002}: 11–16). However, based on evidence suggesting that humans often categorize objects (standard examples include types of birds or furniture, or similar semantic categories) by similarity and often with varying degrees of fuzziness, cognitive theories like \textit{prototype} \textit{theory} \citep{Rosch1973} and its direct rival \textit{exemplar} \textit{theory} (\citealt{MedinSchaffer1978}; \citealt{Hintzman1986}) were developed. Prototype theory assumes that categories are defined by the similarity of their members to a mentally stored abstraction: the most prototypical member, or, in later versions of prototype theory, weighted features defining the prototype in a non-discrete fashion. Exemplar theory assumes that a category is simply a set of memory traces of previously encountered similar items, and that no abstraction takes place.\footnote{It should be noticed that, technically, the popular schema-based approach in cognitive linguistics (\citealt{Langacker1987}; for an overview, see \citealt{Tuggy2007}) is close to the Aristotelian tradition w.r.t. discreteness of class membership (cf. also \citealt{DivjakArppe2013}: 225–226). However, it has been argued that under the appropriate interpretation, prototypes and schemas are compatible, albeit fulfilling different roles in the cognitive linguistic architecture (\citealt{Langacker1987}, summarized in \citealt{Taylor2003a}: 69–72).} Both theories can deal with certain members of categories being \textit{better} or more central than others, as well as category membership being determined to varying degrees based on similarity rather than on a fixed set of necessary features defining strictly discrete categories (cf. also \citealt{DivjakArppe2013}: 224).\footnote{Close relatives of exemplar models are so-called analogical approaches. Prominently, \citet{Skousen1989} introduced a model which does without abstraction. Daelemans and van den \citet{Bosch2005} include feature and feature weights, and thus a certain level of abstraction. See Kapatsinski (2014: 4–14; esp. 11–12) for an overview, a comparison and an argumentation in favor of including weighted features in analogical models.} The major difference between them is how they model the cognitive representations of categories, as either abstractions (prototypes) or memory traces of concrete exemplars. The two theories are supported by different sets of experimental methods, such as similarity ratings, typicality ratings, and category naming. See \citet{StormsEtAl2000} as an example of those methods applied to semantic categories in natural language, including a discussion of the relevance of the respective findings for the two theories. It has been suggested by Barsalou (1990: 72–77) that the theories might be informationally equivalent. In the same paper, \citet[63]{Barsalou1990} argues that behavioral experiments fail to produce conclusive evidence for or against either model of cognitive representation, because mental representations cannot be observed directly and experiments always show effects of both the representation and the processes involved in producing participants’ reactions. Barsalou states that

\begin{quote}
we can not say whether category knowledge is distributed in exemplars or centralized abstractions. But we do know that any account of knowledge that excludes idiosyncratic information, cooccurrence information, or dynamic representation is inadequate. \citep[84]{Barsalou1990}
\end{quote}

With this argument in mind, which is even more applicable to corpus-based methods where we can intrinsically only observe the results of categorization made by writers (cf. also \sectref{sec:key:2.2}), I adopt a strictly prototype-theoretical formulation in the remainder of this paper, though I consider my findings to be compatible with alternative theories.\footnote{Cf. also Murphy (2002: 39–65) on how the two theories both overcome the problems of the Aristotelian view in different ways, but with similar results.}

While in her earlier work Rosch conceptualized the representation or the prototype as the most prototypical member of a category (\citealt{Taylor2008}: 42–44), in her later work (\citealt{RoschEtAl1976}; \citealt{Rosch1978}) and in most of the subsequent literature (summarized in \citealt{Taylor2008}: 44–46, 2015: 564), prototypicality is modeled in terms of weighted features. Under this view, an object belongs to a specific category to the extent that it has a sufficiently large number of diagnostic properties, each of which is (at least potentially) not strictly required for membership in that class. To account for effects of similarity and fuzziness of membership, the features are weighted as being more or less characteristic. This is formulated in terms of a high or low \textit{cue} \textit{validity} of a feature (\citealt{RoschEtAl1976}: 384–385). Ideally, the cue validity would specify the conditional probability p(F{\textbar}C) that an item which exhibits a feature F is a member of category C.\footnote{Mathematically different formulations have been proposed within prototype theory and similar cognitive theories of categorization and category learning (e.g., \citealt{BusemeyerEtAl1993} or \citealt{KruschkeJohansen1999}), but the differences are of little importance for the present study.} Obviously, exact cue validities and exhaustive feature sets are hard to establish experimentally; estimating the \textit{relative} importance in a set of relevant features is a more realistic goal. The concept of cue validity is crucial for this study, and it comes with two corollaries which are equally important. The first one is related to the distinction between rule-based and similarity-based categorization: if some prototypical feature is weighted high enough compared to all other features, it might become a de-facto requirement for category membership. Technically, prototype theory based on weighted features thus encompasses the classical Aristotelian approach as a limiting case (\citealt{Taylor2008}: 45, 2015: 564). This is highly important when we apply prototype theory to effects in grammar, where, arguably, categories (such as a word’s membership in an inflectional class) have a much more discrete character than in lexical semantics (see \sectref{sec:key:2.3}). Modeling a continuum between rule-based approaches and similarity-based approaches is thus technically possible within a feature-based prototype theory.\footnote{On the desirability of such a continuum, cf. also Divjak and Arppe (2013: 224–229), citing \citet{Goldberg2006}, \citet{Langacker2010}, etc.} The second corollary is that there is no need to commit to a \textit{single} prototype as the representation of a category, or, alternatively, a \textit{single} cluster of feature values defining the center of the category. Given the relevant features and their weights, there might be multiple more or less dissimilar prototypical subsets of features instantiated in corresponding prototypical representatives, resulting in a polycentric category.\footnote{This is reminiscent of polysemy in lexical semantics, i.e., the association of multiple senses with one form. The difference to classical polysemy, which assumes clearly distinct senses, is that the weighted-feature approach to prototype theory allows for diverse equally prototypical manifestations with varying degrees of similarity. In other words, nothing forces us to assume clearly distinct and/or hierarchically ordered centers of the category, and polycentric categories do not pose a problem. Cf. especially Taylor (2003b, 2006) for a discussion in favor of such a view, although not in the context of prototype theory.}

As mentioned above, prototype theory was first developed with a focus on noun semantics. However, the present study stands in a long tradition of applying prototype theory to grammatical categories (\citealt{Taylor2008}: 51–60, 2015: 568–576). If we regard it as a general model of the organization of cognitive representations, it should be expected to be applicable to grammatical categories. To name just a few examples, prototype effects have been detected in the categorization of strong verbs in English (\citealt{BybeeModer1983}), in part-of-speech classification \citep{Uehara2003}, and in the selection and/or classification of syntactic constructions and the syntax-lexis interface (\citealt{Winters1990}; \citealt{Gries2003}; \citealt{DivjakArppe2013}; Dobrić 2015).\footnote{There are also studies which, although they do not use prototype-theoretical terminology, can be seen as supporting the application of similarity-based theories to grammar, for example Dąbrowska’s \REF{ex:key:2008} exemplar-based study of Polish-speakers’ ability to classify novel nouns with regard to their inflectional class based on, among other things, phonological and morphological similarity to known nouns.} Especially in morphosyntax, large feature sets pertaining to all levels of linguistic description, including features referring to larger linguistic (and even extra-linguistic) contexts can be taken into account, either defining prototypical constructions in which items appear (cf. especially \citealt{DivjakArppe2013}: 228 on the importance of the contextual element) or defining prototypical choices of competing constructions which are prototypically instantiated in certain contexts and given certain lexical choices. Some of the aforementioned studies and the study presented here use corpus data, and I turn to the validity of corpus linguistic methods in prototype theory in Section~2.2.

\subsection{Prototypes, alternations, and corpus data}

With regard to using corpus data to support prototype approaches, two major questions need to be clarified. The first and rather technical question is that of the appropriateness of concrete methods. The second question is more fundamental and concerns the validity of corpus-based experiments in prototype theory and cognitive linguistics in general. I briefly discuss these two questions in this section.

Methodologically, there are diverse approaches to corpus-based prototype research; I provide only an exemplary overview. For example, \citet{Gilquin2006} examines raw and relative frequencies in order to determine how often prototypical properties of English periphrastic causative constructions described in the existing literature are instantiated in corpus exemplars. She sees this as a test of the idea that prototypicality implies salience, which in turn implies high frequency (\citealt{Gilquin2006}: 169, 178), and as a test of the existing theoretical models of prototypical causation (\citealt{Gilquin2006}: 178–180). Dobrić \REF{ex:key:2015} models the prototypicality of the different senses of the English verb \textit{look} by, among other things, counting the number of corpus sentences in which they are instantiated (also under the hypothesis that prototypicality implies high frequency) and by determining how restricted the senses are with respect to the different contexts in which they appear. Another approach does not rely on assumptions about a direct correspondence between prototypicality and absolute frequency and focuses on situations where two or more lexical items or two or more constructions compete (i.e., where they alternate). Some form of multifactorial modeling is then applied to determine how strongly the relevant features influence the choice of each of the competing elements. Under this approach, the features of the multifactorial model define the prototypicality of the competing items, and the calculated probabilities in favor of a specific choice can be seen as an approximation of the cue validity of the features. For example, \citet{Gries2003} examines how a large number of features influences the choice between ditransitive and competing prepositional constructions in English. Similarly, \citet{DivjakArppe2013} model the choice among larger sets of Finnish and Russian \textit{try} verbs, determining prototypical properties for each verb (\citealt{DivjakArppe2013}: 260–267) by applying polytomous regression using a large set of grammatical, lexical, and contextual features extracted from corpus exemplars.\footnote{There is more work along these lines which does not necessarily use prototype-theoretical terminology. For example, Barth and Kapatsinski (2014, ahead of print) use regression techniques to model the circumstances under which English auxiliaries are and are not contracted (\textit{am} vs. \textit{‘m} etc.) in corpus data. Similarly, \citet{BaayenEtAl2013} model four grammatical choices in Russian, using corpus data for three of them.} The present study stands in this line of research.\footnote{For an overview of the available and most popular methods for such tasks, cf. \citet{Gries2014}.}

Finally, I turn to the important question of the validity of corpus-based findings in cognitive linguistics in general and prototype theory in particular. Some general objections against corpus data, which could be seen as applicable here, have been dealt with in Bresnan et al.’s \REF{ex:key:2007} paper on the dative alternation in English.\footnote{Of course, the argumentation in \citet{BresnanEtAl2007} is specific to their research question and the corpus data they used. There is no reason, however, to doubt that the findings generalize to other corpora and research questions.} First of all, Bresnan et al. (2007: 82–84) show that the factors which influence the choice between two alternative constructions are stable across individual speakers represented in the corpus. Corpus data, which pool a large number of individual speakers, can thus still be used to infer regularities of individual speakers’ mental grammars (contra \citealt{Newmeyer2003}, especially p. 696). Similarly, Bresnan et al. (2007: 87–90) show that cross-corpus differences (which might, at least partially, be attributed to different distributions of register or genre) do not per se invalidate grammatical inferences from corpus data. Furthermore, the contributions in \citet{GlynFischer2010} (especially \citealt{GriesDivjak2010}), all argue implicitly or explicitly for the applicability of corpus-based methods in cognitive linguistics, including references to work where corpus-based and experimental work (which offers more direct access to cognitive representations and processes) have been successfully correlated. Thus, there clearly exists a successful research paradigm for corpus linguistics as “psychologically informed (cognitively-inspired) usage-based linguistics” \citep[334]{Gries2010}. For a concrete corpus study, however, it is still important to evaluate the \textit{construct} \textit{validity} of the specific constructs used.\footnote{\textit{Construct} \textit{validity} specifies how well a theoretical construct, which cannot be operationalized directly but is decomposed into a number of operationalizable indicator variables, is measured in an experiment. On the subject of construct validity and test validity in general, see \citet{CronbachMeehl1955}, \citet{CampbellFiske1959}, or the convenient summary in Maxwell and Delaney (2004: Ch.~1).} In prototype theory in the narrow sense, the construct is a cognitive representation of a linguistic category such as the meaning of a word, either in the form of a maximally prototypical exemplar or a set of weighted features (cf. \sectref{sec:key:2.1}). \citet{Gries2003} comments:

Frequently, Rosch’s results were [...] interpreted as if they were statements on the structure of mental representations as such; cf. the \textit{effects=structure} fallacy and the \textit{prototype=representation} fallacy. I do not wish to support such interpretations. [...] Still, even if the form of analysis does not translate into statements on mental representations, the high predictive power [...] shows that the cognitive factors underlying the choice of construction have been identified properly and weighted in accordance with their importance for actual usage. \citep[22]{Gries2003}

Making a significantly stronger claim, \citet{DivjakArppe2013} state:

\begin{quote}
The objectives of this study are, first, to explore how the prototype and exemplar models of categorization manifest themselves in corpus data [...]. Although corpus data do not reflect the characteristics of mental grammars directly, we do consider corpus data a legitimate source of data about mental grammars. (\citealt{DivjakArppe2013}: 229–230)
\end{quote}

However, as Divjak and \citet[224]{Arppe2013} themselves point out (citing \citealt{Barsalou1990}), prototype and exemplar models can be seen as informationally equivalent (cf. also \sectref{sec:key:2.1}), and the relevant difference between them is the level of abstraction assumed in mental representations.\footnote{\citet[15]{Kapatsinksi2014} takes this even further with his hypothetical statement that “[i]n the extreme, some speakers’ heads could host exemplar models, and some could contain fairly abstract grammars, and the produced output would be essentially identical.”} I therefore follow \citet{Gries2003}, taking the safe route and suggesting that if corpus data show the result of similarity-based categorization and fuzziness of categories, they provide support for cognitive linguistic theories of categorization and against traditional linguistic theories. Thus, a lot is achieved if we make sure “that the cognitive factors underlying the choice of construction have been identified properly and weighted in accordance with their importance for actual usage” \citep[22]{Gries2003}.

To sum up, corpus data have been established as a reliable testing ground for cognitive linguistic theory. Prototype theory is well suited to model cases where forms or constructions alternate if we regard the features which control the choice of alternative forms and their weights as defining prototypes or prototypical contexts for their use. The notion of cue validity from prototype theory correlates with the contribution made by single feature values to the probability of a specific alternate being chosen in multifactorial analyses.

\subsection{Prototypes, paradigms, and probabilistic morphology}

As stated above, the focus of this paper is on alternation between two inflectional classes. In this section, I propose to treat this alternation under a prototype view of inflectional morphology, based on Sections 2.1 and 2.2. I also relate the present study to a larger body of work which suggests that a probabilistic usage-based approach to inflectional morphology is appropriate.

The prototype approach to paradigm structure has been followed, for example, by \citet{NessetJanda2010}. They argue that paradigms have a theoretical status (which in cognitive linguistics means a cognitive reality), which is denied in traditional Item-and-Arrangement or Item-and-Process approaches to morphology (see the discussion in \citealt{Bybee1985}). Even more importantly, Nesset and Janda (2010: 705–707) argue that paradigms are structured as \textit{radial} \textit{categories}, with highly central and prototypical, but also marginal exponents. Within verbal paradigms, for example, singular exponents are assumed to be more prototypical than plural exponents, finite exponents more prototypical than infinite ones, etc. Nesset and Janda (2010: 172–173) formulate this as the \textit{Paradigm} \textit{Structure} \textit{Hypothesis} and argue that prototypical (and thereby unmarked) exponents within a paradigm are “more resistant to [...] change”. They show that this assumption is supported by examining ongoing changes in Russian verbal inflection. I will return to this in \sectref{sec:key:2.4} and \sectref{sec:key:3} when looking at differences in case forms of weak nouns in German.

\citet{NessetJanda2010} use prototype theory as their specific background, but the general cognitive framework detailed in Sections 2.1 and 2.2 extends to a more general probabilistic view of morphology supported by the data presented here. I do not go into detail on the concrete theoretical or computational implementations of probabilistic, gradient morphology, following \citet{HayBaayen2005}:

\begin{quote}
[...W]e separate the questions of subsymbolic versus symbolic implementation on the one hand, from discrete versus gradient structure on the other. The results [...] could potentially be modelled both by symbolic and non-symbolic approaches. However, they resist modelling by strictly deterministic, non-probabilistic approaches. (\citealt{HayBaayen2005}: 342–343)
\end{quote}

There is ample support for the view that grammar is inherently probabilistic (overviews in \citealt{HayBaayen2005} or \citealt{Kapatsinski2014}), and it is not necessary to review that evidence extensively here. The one aspect I want to point out is that probabilistic analogical effects in inflectional morphology have been diagnosed not just for irregular forms (like strong verbs in English), but also in the formation of completely regular forms (\citealt{ErnestusBaayen2004}; \citealt{TabakEtAl2010}; \citealt{RamscarEtAl2013}). The emerging picture shows that phonology, semantics, frequency, and similarity to other items drive analogical processes in both irregular and regular inflection. This is relevant for the present study because weak nouns in German cannot be called irregular, but their inflection is nonetheless affected by probabilistic effects.

Finally, the token frequency of specific items and the type and token frequencies of a pattern (such as an inflectional class) are assumed to play a role under cognitively oriented usage-based theories, although modeling exact effects and interactions is complex (cf. for example, \citealt{Bybee1985}; \citealt{Langacker1987}; \citealt{Schmid2010a}; Divjak and Caldwell-\citealt{Harris2015}; a discussion with a focus on corpus data is provided in \citealt{Schmid2010b}). In general, it is assumed that high token frequency of an individual item leads to entrenchment of that item (\citealt{Langacker1987}: 59–60). In other words, what is frequently repeated individually gradually becomes stored individually, and is easier to access and less susceptible to analogy (\citealt{BybeeHopper2001}). On the other hand, high type frequency (i.e., the frequent occurrence of different items in a certain structure) favors the storage of an abstract and productive pattern of that structure (\citealt{BybeeThompson2000}). Divjak and Caldwell-\citet{Harris2015} summarize further developments and the experimental techniques being used to examine frequency effects, as well as the ongoing discussion about the problems involved in the interpretation of results. I include only simple lemma token frequencies in the statistics in \sectref{sec:key:3} (cf. especially \sectref{sec:key:3.3}), and therefore do not go into further detail here.

\section{The German weak-noun prototype(s)}

In this section, I provide an analysis of the relevant aspects of the German weak-noun inflection. The aim is to derive testable hypotheses for the corpus study presented in \sectref{sec:key:3} considering the theoretical background specified in Sections 2.1 through 2.3. Some of the details discussed by \citet{Köpcke1995} – especially diachronic aspects – are not dealt with prominently here.

\begin{table}
\caption{ The two weak-noun prototypes and their features with example nouns from \citet[178]{Köpcke1995}.}
\label{tab:2}
\end{table}

\citet{Köpcke1995} establishes two major prototypes for weak nouns, thus effectively defining a polycentric (bifocal) category (cf. \sectref{sec:key:2.1}). The two types of prototypical weak nouns are analyzed as bearing the semantic and phonotactic features summarized in \tabref{tab:key:2} (derived from Köpcke’s 1995: 178 diagram), where the degree of prototypicality is encoded vertically. Semantically, weak nouns denote humans (highest cue validity), animate objects, or inanimate objects (lowest cue validity). The other features are phonotactic, and their weightings are more complicated, as should become clear immediately when looking at \tabref{tab:key:2}. Final schwa is highly characteristic of prototype I.\footnote{\citet[119]{Köpcke2000} even goes so far as to call the final schwa a marker of humanness or even agentivity for masculine nouns of prototype I. Indeed, there are only a few masculine (weak) nouns ending in schwa which do not denote humans (\textit{Affe} ‘ape’, \textit{Löwe} ‘lion’, etc.). This interesting quasi-causal relationship between form and lexical meaning is a far-reaching interpretation which cannot be tested in a corpus study, and is therefore left aside here.} Furthermore, prototype I has penultimate accent, and prototype II has ultimate accent except for the words ending in schwa. This falls out because schwa can never be accented in German. Nearly all weak nouns are polysyllabic, with the exception of the Germanic monosyllables in prototype I (those without final schwa). Clearly, the phonotactic features are not independent, and they will consequently be coded as one factor with the appropriate levels in the corpus study in \sectref{sec:key:3.} Interestingly, the semantic property of denoting humans (or animals) is not even remotely exclusive to weak nouns. On the other hand, polysyllabic nouns with non-initial accent are quite atypical and relatively rare because the dominant phonotactic pattern for nouns is monosyllabic or trochaic (\citealt{Eisenberg2012}: 18–19, \citealt{Eisenberg2013}: Ch. 5). I therefore suggest that the phonotactic features must be expected to be more salient than the semantic features as cues for the class of weak nouns.

Some weak nouns have become fully or mostly strong (\citealt{Wurzel1985}; \citealt{Joeres1996}) over time, and Köpcke argues, mostly based on diachronic data, that the assimilation to the more productive strong inflection was controlled mainly by the semantics of the respective nouns. Nouns denoting humans or animals (especially animals strongly linked to humans such as farm animals or pets) are more immune to becoming strong. However, while some individual weak nouns have become strong, Köpcke does not consider the class of weak nouns to be generally eroding:

Mit zunehmender Entfernung von den Prototypen nehmen Übergangsprozesse von schwacher zu starker Deklination zu. Abbautendenzen für die schwachen Maskulina finden aber ausschließlich in der Peripherie des Kontinuums statt; der prototypische Bereich ist hiervon nicht betroffen. Im Gegenteil: Hier lassen sich Aufbautendenzen beobachten. [With a larger distance from the prototype, it is more likely that a weak noun shows transitional phenomena towards the strong declension. However, full transition of weak nouns to the strong declension only occurs in the periphery of the continuum, and prototypical members are not affected. On the contrary: here we even find the opposite, i.e., strong nouns becoming weak.] (\citealt{Köpcke1995}: 159–160)

In \sectref{sec:key:3}, I will therefore seek first of all to determine how stable is the class of weak nouns in a corpus of contemporary German, and argue that a purely synchronic view on the phenomenon is justified. If morphology is inherently probabilistic (\sectref{sec:key:2.3}) and similarity-based (\sectref{sec:key:2.1} and 2.2), and if the weak-noun prototype does have a cognitive reality, then we should expect to find a certain number of strong forms of weak nouns. It has already been demonstrated in \sectref{sec:key:1} that this is the case. If the class is stable, however, the strong forms should be rare. Furthermore, the more prototypical a weak noun, the lower should be its probability of occurring in a strong form. Under this hypothesis, the alternation strength is an indirect indicator of the cue validity of the features summarized in \tabref{tab:key:2}, and a corpus study can provide an evaluation of the relative cue validities of the features. These hypotheses constitute the theoretical core of \sectref{sec:key:3.}

An additional factor is contextual in the sense of \sectref{sec:key:2.2}, namely the grammatical case of the nouns. Thieroff (2003: 113–115) argues that it is natural for weak nouns to occur in strong forms from a paradigmatic perspective. He derives this conclusion from the fact that weak nouns violate very productive generalizations of case inflection of German nouns in general and masculine nouns in particular. First of all, the accusative and dative singular of all other nouns (masculine or otherwise) are never suffixed and are thus formally identical to the nominative singular base form.\footnote{The dative singular marker \nobreakdash-\textit{e} is now virtually extinct in contemporary German.} This is the most productive generalization because it concerns all German nouns, except for the roughly 450 weak nouns. Secondly, the genitive singular of masculine nouns is otherwise always distinguishable from the accusative and the dative because the genitive is marked (i.e., not identical to the nominative base form), and the accusative and dative are not. Thirdly, the genitive marker (if there is one) is otherwise always \textit{\nobreakdash-es}.\footnote{These generalizations are implicitly or explicitly accepted by most German grammarians, e.g., Eisenberg (2013: Ch. 5) or Schäfer (2015: Ch. 8).} These generalizations are relevant to this study because I assume that paradigms have an internal structure and a cognitive reality (cf. \sectref{sec:key:2.3} and the detailed overview in \citealt{NessetJanda2010}: 704–705), and that it consequently matters which formal oppositions within the paradigm are salient. Clearly, the most productive and therefore most salient of the relevant generalizations about nominal paradigms in German (i.e., the identity of all accusative and dative singular forms in relation to the respective nominative singular base form) as well as the second (the formal distinguishability of the masculine genitive singular from the accusative and dative singular) are satisfied by making only the accusative and the dative strong and leaving the genitive weak. Only the third generalization (masculine genitive singular forms have \textit{\nobreakdash-es}) requires even the genitive of weak nouns to become strong. I therefore expect that the probability of finding strong forms of weak nouns is lower in the genitive than in the accusative and dative.

To summarize the hypotheses for the corpus study in \sectref{sec:key:3}: (i) I expect to find a low-frequency alternation effect in the sense that weak nouns occur in strong inflectional forms, but with low frequency. In other words, there is no general erosion of the weak nouns, and the class is stable, especially because it is associated with a strong prototype. (ii) Furthermore, I expect the probability of the alternation to be higher in the absence of the prototypical lexical features of weak nouns, namely semantics (human – animate – inanimate) and phonotactics. (iii) The grammatical case of the noun is also expected to affect the alternation strength because the analogical attraction exerted by the more productive strong paradigms is stronger in the accusative and dative than in the genitive. (iv) In accordance with what was said about frequency in \sectref{sec:key:2.3}, a higher token frequency is expected to gradually help prevent the alternation. If supported by corpus data, these hypotheses strengthen the general research program of corpus-based cognitive linguistics and provide welcome support for similarity-based models of categorization.

\section{Corpus study}

\subsection{Challenges and corpus choice}

For a corpus-based account of the factors that influence the strength of the alternation of weak nouns towards the strong pattern, the source of data has to satisfy two requirements, which are not satisfied by most available corpora. First, the corpus has to contain unedited spontaneous writing because the strong forms of weak nouns are very rare in standard written German. Occurrences in professionally written media like \REF{ex:key:1b} in \sectref{sec:key:1} are exceptional. Secondly, as the phenomenon is rare, an appropriate corpus should be as large as possible. The size requirement is even more vital because the strong forms turned out to be so rare that we cannot locate them in an acceptable time by going through large concordances manually.\footnote{This can be illustrated using a slightly simplified calculation. In \sectref{sec:key:3.2}, I show that only 2.8\% of the occurrences of weak nouns are strong. This means that in order to find one strong exemplar by hand, we have to look at 36 concordance lines on average. There are 451 weak noun lemmas in my sample. So, even in order to find one strong exemplar of each noun, we would have to go through 36 {\textbullet} 541 = 16,107 concordance lines. A manual search is clearly not feasible, and an automatic approach is required, even if it has high precision but low recall.} This means that only co-occurrences of weak nouns with the singular indefinite determiner can be used, as I will argue now.

Consider the forms whose frequencies are to be compared, shown in \tabref{tab:key:1}.1. German masculine determiners have unambiguous case forms in the singular, so it appears that we could just search for sequences of an appropriately inflected determiner, optionally followed by zero, or more appropriately inflected adjectives followed by a weak-noun lemma. However, NPs containing the canonical accusative singular are (as a whole phrase) homonymous with those containing the accusative or dative plural, as can be seen in \tabref{tab:key:1}.1. This makes it impossible to search for canonical forms with determiners that have a plural without having to fall back on the manual inspection of huge concordances. The only determiner without a plural is \textit{ein} ‘a’ because indefinite plural NPs are determinerless in German. As a quantifier, \textit{ein} ‘one’ is semantically blocked from occurring in the plural. This reduces the unambiguous NP configurations to those with the determiner \textit{ein}.

Because of the problems of data sparseness, the DECOW12A web corpus was chosen.\footnote{The corpus was built and is hosted by Freie Universität  Berlin. Information can be found at: http://corporafromtheweb.org/decow14/} It is part of the COW collection of web corpora and contains 9.1 billion tokens, making it the largest linguistically annotated corpus of German available at the time this study was conducted.\footnote{In the meantime, it has been superseded by the 20.5-billion-token DECOW14A, which is a superset of DECOW12A. There are other COW corpora available in Dutch, English, French, Spanish and Swedish.} Furthermore, it can be downloaded in sentence-shuffled form for local processing. Since not much is known about the properties of large web corpora from a linguistic perspective, I briefly argue for the use of this resource here. The DECOW corpus was described by its creators in \citet{SchäferBildhauer2012} and \citet{SchäferBildhauer2013}. Schäfer and Bildhauer (2012: 492–493) and \citet[48]{BiemannEtAl2013} present an assessment of the text types and registers contained in the corpus based on manually annotated samples, showing that the corpus contains an estimated 22.5\% of documents written in a \textit{quasi-spontaneous} mode, i.e., mostly forum discussions. This is the kind of text where we can hope to find most non-standard strong forms of weak nouns. Biemann et al. (2013: 37–46) also show that the COW corpora compare favorably to traditional and web corpora in extrinsic evaluations (such as collocation extraction tasks). In \citet{SchäferSayatz2014}, DECOW12A was used for similar reasons as in this study, and Van \citet{GoethemHiligsmann2014} base part of their corpus study on the Dutch COW corpus (NLCOW12A) for comparable reasons, too. The use of similar, earlier web corpora like the WaCky corpora (Baroni et al., 2009) has been argued for convincingly by, among others, Zeldes (2012: 96–98). The corpus I have chosen here can therefore be considered a recent but adequately tested source of data.

In the next section, I describe my method of obtaining reliable counts from these data sources by formulating precise queries in a spirit comparable to that of Zeldes, who states (writing about his work with the WaCky corpora) that

[t]his type of automatically retrieved data is rather heterogeneous and possibly error-prone, so a main priority in searching through such corpora is to ensure high accuracy of results by formulating precise queries and manually evaluating error rates as required. \citep[97]{Zeldes2012}

However, heterogeneity in the data is also a blessing because it increases the external validity of a study, i.e., the probability that the findings generalize well (\citealt{MaxwellDelaney2004}:~30). Considering that corpora like DECOW allow us to take very large samples, the error-prone or noisy nature of the data is also less of a problem because the error is distributed randomly, at least if there is no systematic sampling error.

\subsection{Sampling and descriptive statistics}

To derive a sample for the analysis of the counts of weak and non-canonical strong uses of weak nouns, I proceeded as follows. First, a list of weak nouns was bootstrapped from DECOW12A by searching for word forms ending in \textit{en} and preceded by a determiner in the genitive (such as \textit{des} \textit{Planeten} ‘of a planet’). Using this bootstrapping method requires each selected noun to occur at least once in a canonically inflected genitive form with a determiner and without an adjective. This is a desirable by-effect because it ensures that no extremely infrequent nouns make it into the final sample. The list was sifted by hand in order to eliminate erroneous matches, including strong nouns in weak forms (however, see the discussion in \sectref{sec:key:3.4}). In total, 451 noun lemmas were found, which is highly consistent with \citet[98]{Bittner2003}, who states that 40 native and more than 400 non-native lemmas fall into the class of weak nouns.

Then, the final sample was taken by querying inflected non-nominative singular forms of \textit{ein} (accusative \textit{einen}, dative \textit{einem}, genitive \textit{eines}), optionally followed by properly inflected adjectives, followed by either the weak or the strong form of each of the bootstrapped lemmas. In total 451 lemmas {\textbullet} 3 cases {\textbullet} 2 alternative forms = 2,706 queries were executed.\footnote{A sample query as performed in the IMS OCWB (\citealt{EvertHardie2011}): [word="einen"\%c] [pos="ADJA" \& word=".+en"]* [word="Abiturient"\%c]} In the resulting sample (n~=~953,117), there were 26,667 token occurrences of the strong inflectional pattern and 926,450 token occurrences of the weak inflectional pattern. Accounting for a mere 2.8\% of all occurrences, the use of strong inflection can thus be considered a rare event.%
\footnote{A list of the noun lemmas and their frequencies in the final sample can be found in the appendix. The confidence intervals for the proportion of strong forms specified there (per lemma) are large, which indicates that analyzing the alternation strengths of single lemmas is not a good idea from a statistical point of view.}

Some of the lemmas turned out to be problematic and were removed as follows. Some have homonyms which are frequent proper names, which always inflect according to the strong pattern. German proper person names also occur with determiners, not just in di\-alects, but also in certain styles of writing \REF{ex:key:4}.\footnote{http://www.breitnigge.de/2011/01/14/so-schnell-sind-23-tage-winterpause-rum/}

\ea%4
    \label{ex:key:4}
    \gll\\
        \\
    \glt
    \z
          Ich  werde  lieber    mit   einem  Götze  Zweiter
I  become  rather    with  a    Götze  second
als  mit  einer    Amoroso-Diva  Erster!
than  with  an    Amoroso diva  first
‘I would rather finish second with a guy like Götze than first with a diva like Amoroso!’

Other problematic nouns are those few for which it is known that they have been alternating strongly between weak and strong variant for a long time, some even having re-analyzed alternative stems ending in \nobreakdash-\textit{en} (e.g., strong \textit{Frieden} ‘peace’ with the genitive \textit{Friedens} versus the older but co-existing weak \textit{Friede} with the genitive \textit{Frieden}). In some cases, the differentiation of stems correlates with a semantic differentiation (\citealt{Köpcke1995}: 173; also \citealt{Wurzel1985} and \citealt{Joeres1996}). For the corpus study, this means that these nouns introduce an ambiguity between accusatives and datives of the reanalyzed stem without a suffix (e.g., \textit{dem} \textit{Frieden}) and accusatives and datives of the older stem with a suffix (e.g., \textit{dem} \textit{Friede\nobreakdash-n}). This ambiguity cannot be resolved automatically. They also have a highly increased alternation strength compared to the other weak nouns, for example 13\% strong forms for \textit{Friede}. These facts indicate that they do not belong to the otherwise homogeneous group of weak nouns without reanalyzed stems and but with low alternation strength. Therefore, I decided to remove them from the sample.\footnote{Recall from \sectref{sec:key:2.4} that I do not attempt a diachronic interpretation. Excluding the very few nouns which might actually be undergoing diachronic change is in line with this decision.} A small class of nouns was removed because the sample was contaminated with very recent English loans (always strong) such as \textit{Artist} ‘artiste’ (old loan, weak) vs. ‘artist’ (recent loan, strong). The noun \textit{Steinmetz} ‘mason’ was also removed because it has almost completed a development into a strong noun already (without stem reanalysis). The noun \textit{Mensch} ‘human’ with 221,210 occurrences is extremely frequent and occurs over eight times more often than the next most frequent weak noun \textit{Kunde} ‘customer’, with 26,576 occurrences. I removed it because otherwise the sample would have contained an extremely large proportion of token occurrences of this single noun. The nouns which were removed are still included in the list in the appendix.

The reduced sample contains 433 lemmas and 466,922 token occurrences, of which 10,488 are strong and 456,434 weak. The proportion of strong forms drops by 0.6\% to 2.2\%, which is mostly due to the removal of the nouns with two stems. However, there remains a very large sample of nouns showing the low-frequency alternation effect. \figref{fig:key:1} shows a bagplot of the reduced sample, where each dot represents a weak noun, and the coordinates correspond to the total number of occurrences in the corpus (x-axis for strong, y-axis for weak occurrences). Bagplots \citep{RousseeuwEtAl1999} are bivariate boxplots. The inner polygon (\textit{bag}) contains half of the points. The outer polygon (\textit{fence}) is the bag grown by a factor of three. Data points outside the fence are considered outliers. This bagplot shows that there are many infrequent and few frequent nouns in the sample, which is trivially expected given the power-law distribution of word frequencies. However, we can also tell from the scales of the axes that the strong forms (x-axis) are very rare compared to the weak forms (y-axis). Outliers are few, and I decided against further removal of them.

\begin{figure}
\caption{Bagplot of the distribution of the weak and the strong forms. Each dot represents one lemma. Seven outliers are not shown.}
\label{fig:key:1}
\end{figure}

Because the influence of grammatical case was introduced as an additional factor on top of the features established by Köpcke (\sectref{sec:key:2.4}), a monofactorial descriptive analysis was performed to confirm that case was at least likely to have an effect. It was quite obvious that in the three grammatical cases there were remarkable distributional differences between strong and weak forms. See \tabref{tab:key:3} for an overview of the proportions in the three cases. In the accusative and dative, the strong inflection is much more frequent.\footnote{Notice how the large sample sizes allow estimation of the population proportions with very high confidence.}

\begin{table}
\caption{Proportions of strong occurrences of weak nouns by grammatical case with 99\% confidence intervals and sample size.}
\label{tab:3}
\end{table}

\subsection{A statistical model of the prototype}

In this section, I present inferential statistics which show that the strength of the al\-ternation of weak nouns towards the strong inflection is both influenced by prototypical features of weak nouns and by preferences for case marking in the three grammatical cases. I estimate a Generalized Linear Model (GLM) in order to test for the significance of factors and quantify the strength of the significant factors.\footnote{All calculations were performed using the R statistics software (R Core \citealt{Team2014}), specifically the \textit{glm()} function to fit the GLM. My approach to regression is guided by \citet{FahrmeirEtAl2013} and \citet{ZuurEtAl2009}.} Following the argumentation from \sectref{sec:key:2.4}, the odds associated with the different features can be interpreted as related to their cue validity, and the prototypicality of concrete nouns can be specified by calculating their cumulated odds.

Multifactorial modeling is required since the factors which play a role by hypothesis (cf. \sectref{sec:key:2.4}) are, at least, as follows: (i) the semantic class of the noun (human, animate non-human, inanimate), (ii) final schwa (yes, no), (iii) accent (final, non-final), and (iv) case (accusative, dative, genitive), and (v) token frequency. A binomial Generalized Linear Model based on token occurrences of weak nouns with the aforementioned factors as regressors and weak/strong as the response variable is a reasonable choice. With regard to the coding of the phonotactic variables, it should be noticed (cf. \sectref{sec:key:2.4}) that schwa syllables never take the accent, that monosyllabic words never contain schwa syllables, and that monosyllabic words offer no choice as to where the accent is placed. Consequently, atomic phonotactic variables are not independent. I therefore coded the nouns for a single phonotactic regressor variable (\textit{Pt}) with the levels \textit{PolyUlt} for polysyllabic words with final accent, \textit{PolyNult} for polysyllabic words with non-final accent, \textit{PolySchwa} for polysyllabic words ending in schwa (and consequently with non-final accent), and \textit{Mono} for monosyllabic words. \tabref{tab:key:4} summarizes the response variable, the regressors and their levels, including the simple (log-transformed) token frequency of the lemma (\sectref{sec:key:2.3} and \sectref{sec:key:2.4}).

\begin{table}
\caption{Variables used in the GLM reported in \sectref{sec:key:3.3.}}
\label{tab:4}
\end{table}

As was shown in \sectref{sec:key:3.2}, strong forms of weak nouns are rare (2.2\% of all remaining forms). This makes logistic regression problematic, and special procedures exist for so-called \textit{rare-events} \textit{regression}. I opted for a straightforward approach to this, taking a stratified sample where both outcomes are represented in equal proportions. Models estimated based on such artificially stratified samples are not useful for making predictions about the actual occurrence of events. This means that the coefficients and odds of the GLM can be interpreted only as indicators of the relative cue validities of the different features, and not directly as cue validities. The final sample used to estimate the GLM parameters contained 10,000 data points: 5,000 weak-noun exemplars in weak form and 5,000 exemplars in the strong form.

\begin{table}
\caption{Summary of the binomial GLM reported in \sectref{sec:key:3.3.} Response: strong inflection (non-canonical, positive coefficients) vs. weak variants (canonical, negative coefficients). β is the estimated coefficient and O the odds ratio. n~=~10,000. VIF(Case)~=~1.020, VIF(Sem)~=~1.164, VIF(Pt)~=~1.157, VIF(LogFreq)~=~1.077. Analysis of deviance (for fully specified model df~=~12,170, for intercept-only model df~=~13,863) with χ²: p~<~0.001. Nagelkerke R²~=~0.21.}
\label{tab:5}
\end{table}

I ran standard model diagnostics (analysis of deviance, pseudo-R²), and ensured that there was no severe collinearity by calculating the generalized variance inflation factors (VIF) according to \citet{FoxMonette1992}. \tabref{tab:key:5} summarizes the model. All regressors remained in the model after running an AIC-based step-down procedure.\footnote{A word on model selection is in order at this point. Consider the facts that collinearity is low, that the number of regressors is low, and that the regressors are selected based on strong theoretical assumptions. More advanced methods of model selection, in particular multimodel inference (introduced in \citealt{BurnhamAnderson2002} and used in the linguistics literature, for example, in \citealt{KupermanBresnan2012} and \citealt{BarthKapatsinski2014} [ahead of print]) are simply not required here. Notice that Burnham and \citet[4]{Anderson2002} state that “[s]imple models with only 1–2 parameters are not the central focus of this book; rather, we focus on models of more complex systems.”} The proportion of variance explained by the model is fairly substantial with R²\textsubscript{Nagelkerke}~=~0.21, but not very high. Readers might speculate that a mixed model (GLMM) could attribute some of this unexplained variance to lemma-, writer-, or even genre-specific random effects (cf. \citealt{KupermannBresnan2012}: 594; \citealt{Gries2015}). First of all, it should be noticed that \textit{Sem}, \textit{Pt}, and \textit{LogFreq} are lemma-level regressors anyway. I tried passing \textit{lemma} as a random effect using the \textit{glmer()} function from the \textit{lme4} package in \textit{R} \citep{BatesEtAl2015}, which would effectively to turn the model into a true multilevel model (\citealt{GelmanHill2006}: 266), but the high number of different lemmas and the low counts for strong occurrences per lemma made it impossible to achieve convergence. \textit{Speaker} or rather \textit{writer} as a random effect are not available because authorship is usually unknown in web corpora. Furthermore, the high number of writers in very large samples from corpora as huge and diverse as DECOW makes it very likely that writer-specific random effects cannot be calculated due to extreme numbers of levels. In other words, virtually each sentence is written by a different person.

The intercept models those factor levels which most strongly favor the weak forms by hypothesis over the non-canonical strong forms by hypothesis (\textit{SemHum}, \textit{PtPolySchwa}, \textit{CaseGen}). The accusative (O~=~1.738) and the dative (O~=~2.237) both cause a significant tendency towards the strong inflection compared to the genitive, which is modeled by the intercept. The same is true if the noun denotes inanimate (O~=~1.795) or non-human animate objects (O~=~1.943), compared to humans. There is no interpretable difference between animal-denoting nouns and nouns denoting inanimate objects, however. The phonotactic effects are more extreme than the effects of case and semantics. Non-final accent in polysyllabic words (O~=~16.963) favors the strong pattern most clearly, followed by monosyllabicity (O~=~7.891) and final accent in polysyllabic words (O~=~2.925). The stronger contrasts between the levels of the phonotactic variable are expected because the phonotactic prototypical features are much closer to being exclusive of weak nouns compared to humanness of denotation. In other words, the hypotheses from \sectref{sec:key:2.4} are fully supported by the data.\footnote{I also tried to estimate a GLM with an interaction between \textit{Pt} and \textit{Sem}. However, while animateness and non-ultimate accent showed a significant interaction, Nagelkerke’s pseudo-R² did not increase, while the standard errors and variance inflation factors increased dramatically. I therefore decided to work with the simpler model as reported above.} We can now use the coefficients or odds to amend \tabref{tab:key:2}. Specifically, for the sample nouns ordered according to their assumed prototypicality by \citet[178]{Köpcke1995}, we can specify the overall alternation strength as an inverse indicator of their prototypicality by calculating summed odds (cf. \tabref{tab:key:6}).\footnote{Since a coefficient P for dummy-coded binary variables can be interpreted \textit{ceteris} \textit{paribus}, we can calculate the effect of two coefficients P\textsubscript{1} and P\textsubscript{2} simply as P\textsubscript{1+2}~=~P\textsubscript{1}~+~P\textsubscript{2}, or in terms of odds as O\textsubscript{1+2}~=~exp(P\textsubscript{1}~+~P\textsubscript{2}).} With one negligible deviation (\textit{Gedanke}), the predictions derived from \citet{Köpcke1995} are confirmed, and the alternation strength increases towards the bottom of the table.

\begin{table}
\caption{The nouns from \tabref{tab:key:2} with the estimates of summed odds from the GLM reported in \tabref{tab:key:5} as indicators of their prototypicality. The nouns are merely examples of their respective sub-types.}
\label{tab:6}
\end{table}

Finally, a higher token frequency of a weak noun (measured as log-transformed token frequency per million tokens, moved into the positive range) disfavors its occurrence in strong forms (O~=~0.683). Again, this is in line with the predictions because frequent individual items are expected to be more resistant to analogy through entrenchment (\sectref{sec:key:2.3}). The high relative type frequency of the strong nouns compared to the weak nouns, on the other hand, makes it plausible that an otherwise stable class (\sectref{sec:key:2.4}) shows a consistently measurable alternation effect in the first place. While being less productive than the strong pattern, the weak pattern should still be marginally productive when it is associated with an underlying prototype. In \sectref{sec:key:3.4}, I show how such a marginal productivity can be observed as a kind of reverse alternation effect.

\subsection{Weak nouns as a productive pattern: strong nouns in weak forms}

If predominantly strong nouns with the prototypical properties of weak nouns could be found in weak forms, this would lend further support to the conceptualization of weak nouns as a prototypically structured category. To show that such noun forms are indeed extant, I now look at a subclass of strong loan nouns which occurred very often in weak forms in the bootstrap sample described in \sectref{sec:key:3.2}, namely masculine Latin loans ending in \textit{\nobreakdash-or}. In line with the findings from \sectref{sec:key:3.3}, all these words qualify as good weak nouns because they have prototypical phonotactic features (polysyllabicity and penultimate accent), and we do in fact find non-standard weak dative forms like \textit{dem} \textit{Autoren} ‘the author’ instead of \textit{dem} \textit{Autor} (strong, standard). Interestingly, the corollary that prototype theory with weighted features allows single features to be so highly weighted that they become a de-facto requirement for class membership (discussed in \sectref{sec:key:2.1}) is supported because strong nouns which do not fulfill the phonotactic requirements simply cannot occur in weak forms. Native speakers will very likely agree that accusatives such as \textit{den} \textit{Wegen} ‘the path’ instead of \textit{den} \textit{Weg} are beyond even peripheral acceptability.

\begin{table}
\caption{Counts of strong and weak occurrences of 62 strong nouns ending in \textit{\nobreakdash-or} by humanness of denotation. n~=~114,486. Considering the size of the sample, significance testing is not required. Odds ratio O(weak{\textbar}human,weak{\textbar}non-human)~=~18.868.}
\label{tab:7}
\end{table}

Interestingly, some of these nouns, such as \textit{Autor} ‘author’, denote humans, while others, such as \textit{Transistor} ‘transistor’, do not. I therefore counted the occurrences of 32 human-denoting and 30 non-human-denoting nouns in strong and weak forms. \tabref{tab:key:7} sums up the results. Clearly, the results from the earlier sections are confirmed, as human-denoting \nobreakdash-\textit{or} nouns have a much stronger tendency to occur in weak forms. The odds ratio reveals that the chance of seeing a weak form of a human-denoting noun is 18.868 times higher than the chance of seeing a weak form of a non-human-denoting noun. The results for strong and weak forms in the three grammatical cases also confirm the results from earlier sections (cf. \tabref{tab:key:8}). The genitive slightly favors the weak pattern compared to the accusative (O~=~1.557) and the dative (O~=~1.511). A higher alternation strength of originally strong nouns towards the weak pattern corresponds with a stronger resistance against the alternation towards the strong pattern for weak nouns.

\begin{table}
\caption{Counts of strong and weak occurrences of 62 strong nouns ending in \textit{\nobreakdash-or} by case. n~=~114,486. Considering the size of the sample, significance testing is not required. Pairwise odds ratios (O) are as follows: O(weak{\textbar}dat, weak{\textbar}acc)~=~1.030, O(weak{\textbar}gen, weak{\textbar}acc)~=~1.557, O(weak{\textbar}gen, weak{\textbar}dat)~=~1.511.}
\label{tab:8}
\end{table}

\section{Conclusions}

In \sectref{sec:key:2}, I made it clear that I do not wish to argue for specific models of mental representation of linguistic categories, but merely for a class of theories which can account for effects of similarity and fuzziness in linguistic categorization. The hypotheses and the predictions for the corpus study developed in \sectref{sec:key:2.4} were nevertheless very specific and could easily have been refuted if (i) cognitive theories of categorization were incorrect, (ii) corpus data were not an appropriate testing ground for such theories, or (iii) the chosen corpus were inappropriate. Since the predicted effects could all be demonstrated, all these scenarios are unlikely. Specifically, I have shown that the prototypical semantic and phonotactic properties of weak nouns as described by \citet{Köpcke1995} influence the alternation strength of those nouns in exactly the direction suggested by the theory: the more prototypical a weak noun is, the lower its probability of occurring in a strong form is. The phonotactic properties, which are more exclusive to weak nouns than the semantic properties, have proven to have a higher cue validity than the semantic properties. Furthermore, the demonstrated significant influence of grammatical case on the alternation strength was expected under a theory which assigns a cognitive status to paradigms and their structure, because the alternation is stronger in those forms of the weak nouns (accusative and dative) which violate most clearly the most productive generalizations about paradigms of German nouns. Finally, the fact that higher lemma token frequencies tend to prevent the alternation from occurring strengthens a usage-based interpretation of the phenomenon. The effects of the noun’s semantics and grammatical case were cross-examined by showing that strong nouns with properties prototypical of weak nouns do in fact occur in weak forms.

From a corpus linguistic perspective, the challenge lay in the fact that the alternative forms occur mostly in non-standard language and are rare, such that a corpus was needed which contained at least some non-standard language, and which was very large. The DECOW12A web corpus was demonstrated to have those properties; in \sectref{sec:key:3.2} I showed how the size of the corpus allows researchers to use high-precision but low-recall techniques of automatic non-manual querying and data processing, while still retrieving large-enough samples. In line with \sectref{sec:key:3.1}, I strongly suggest that this proves the necessity of further development and exploration of freely available web corpora as an invaluable source of insight for quantitative corpus linguistics.

While further work specifically on the weak nouns might include a more systematic look at the productivity of the class in terms of its power to attract strong nouns like the \textit{\nobreakdash-or} subclass described in \sectref{sec:key:3.4}, a more general look at similar alternations in the morphosyntax of German under a cognitive perspective should also be highly fruitful. German is famous for its grammatical \textit{Zweifelsfälle} ‘cases of doubt’, including many instances of co-existing, alternating forms in nominal and verbal morphology and blurred boundaries between standard and non-standard language. While the rich and insightful existing literature is largely descriptive, diachronic, structuralist, or even normative (cf. \citealt{Klein2009}), the phenomena are ideal for cognitive explorations such as that undertaken in this paper, and they have great potential for strengthening the usage-based linguistics paradigm in general, but also the position of corpus linguistics within it.
